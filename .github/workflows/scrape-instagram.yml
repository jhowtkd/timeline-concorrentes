name: ğŸ“¸ Instagram Scraper - Concorrentes

on:
  # Agendado: todo dia Ã s 9h UTC (6h BRT)
  schedule:
    - cron: '0 9 * * *'
  
  # Manual trigger (para testes)
  workflow_dispatch:
    inputs:
      limit:
        description: 'NÃºmero de posts por perfil'
        required: false
        default: '50'

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“¥ Checkout do cÃ³digo
        uses: actions/checkout@v4
      
      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
      
      - name: ğŸ“¦ Instalar dependÃªncias
        run: npm ci
      
      - name: ğŸš€ Executar Scrape (Baseado no Banco)
        run: npx tsx scripts/scrape-from-db.ts ${{ github.event.inputs.limit || '50' }}
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
          CLAUDBOT_API_KEY: ${{ secrets.CLAUBOT_API_KEY }}
          APIFY_ACTOR_ID: apify/instagram-scraper
          INGEST_API_URL: ${{ secrets.INGEST_API_URL }}
        continue-on-error: true
      
      - name: ğŸ“Š Upload de logs (em caso de falha)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-logs-${{ github.run_id }}
          path: logs/
          if-no-files-found: ignore

  notify:
    needs: scrape
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: âœ… Notificar sucesso
        if: needs.scrape.result == 'success'
        run: echo "ğŸ‰ Scrapes concluÃ­dos com sucesso!"
      
      - name: âš ï¸ Notificar falhas parciais
        if: needs.scrape.result == 'failure'
        run: echo "âš ï¸ Alguns scrapes falharam. Verifique os logs."
